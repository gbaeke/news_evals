{
  "flow_runs": [
    {
      "run_id": "1e3d52e8-08f4-4fe5-87ba-392596966feb_0",
      "status": "Completed",
      "error": null,
      "inputs": {
        "content": "Azure AI Agents Service simplifies building intelligent agents by combining advanced AI models, tools, and technology from Microsoft, OpenAI, and partners like Meta and Cohere. It enables integration with knowledge sources such as Bing, SharePoint, and Azure AI Search, and lets agents perform actions across Microsoft and third-party applications using Logic Apps, Azure Functions, and Code Interpreter. With Azure AI Foundry, you get an intuitive agent-building experience, backed by enterprise-grade features like customizable storage, private networking, secure authentication, and detailed observability through OpenTelemetry.  At the time of this writing (December 2024), Azure AI Foundry did not provide a user interface yet to create these agents in the portal. In this post, we will use the Azure AI Foundry SDK to create the agent from code.  You can find the code in this repository: https://github.com/gbaeke/agent_service/tree/main/agentui  How does it work? The agent service uses the same wire protocol as the Azure OpenAI Assistants API. The Assistants API was developed as an alternative to the chat completions API. The big difference is that the Assistants API is stateful: your interactions with the AI model are saved as messages on a thread. You simply add messages to the thread for the model to respond.  For more information, check this video:   To get started, you need three things:  An agent: the agent uses a model and instructions about how it should behave. In addition, you add knowledge sources and tools. Knowledge sources can be files you upload to the agent or existing sources such as files on SharePoint. Tools can be built-in tools like code interpreter or custom tools like any API or custom functions that you write. A thread: threads receive messages from users and the assistant (the model) responds with assistant messages. In a chat application, each of the userâ€™s conversations can be a thread. Note that threads are created, independent of an agent. The thread is associated with the agent when you add a message. Messages: you add messages to a thread and check the thread for new messages. Messages can contain both text and images. For example, if you use the code interpreter tool and you asked for a chart, the chart will be created and handed to you as a file id. To render the chart, you would need to download it first based on its id. Creating the agent Before we create the agent, we need to connect to our Azure AI Foundry project. To do that (and more), we need the following imports:  import os from azure.ai.projects import AIProjectClient from azure.ai.projects.models import CodeInterpreterTool from azure.identity import DefaultAzureCredential from fastapi import FastAPI from typing import Dict from azure.ai.projects.models import FunctionTool, ToolSet from typing import Any, Callable, Set, Dict from fastapi.middleware.cors import CORSMiddleware from pydantic import BaseModel import requests import base64 We will use the AIProjectClient to get a reference to an Azure AI Foundry project. We do that with the following code:  # Set up credentials and project client credential = DefaultAzureCredential() conn_str = os.environ[\"PROJECT_CONNECTION_STRING\"] project_client = AIProjectClient.from_connection_string(     credential=credential, conn_str=conn_str ) Note that we authenticate with Entra ID. On your local machine, ensure you are logged on via the Azure CLI with az login. Your account needs at least AI Developer access to the Foundry project.  You also need the connection string to your project. The code requires it in the PROJECT_CONNECTION_STRING environment variable. You can find the connection string in Azure AI Foundry:   AI Foundry project connection string We can now create the agent with the following code:  agent = project_client.agents.create_agent(     model=\"gpt-4o-mini\",     name=\"my-agent\",     instructions=\"You are helpful agent with functions to turn on/off light and get temperature in a location. If location is not specified, ask the user.\",     toolset=toolset ) Above, the agent uses gpt-4o-mini. You need to ensure that model is deployed in your Azure AI Foundry Hub. In our example, we also provide the assistant with tools. We will not provide it with knowledge.  Whatâ€™s inside the toolset?  built-in code interpreter tool: provides a way for the model to write Python code, execute it and provide the result back to the model; the result can be text and/or images. custom tools: in our case, custom Python functions to turn on/off lights and look up weather information in a location. There are other tool types that we will not discuss in this post.  Adding tools Letâ€™s look at adding our own custom functions first. In the code, three functions are used as tools:  def turn_on_light(room: str) -> str:     return f\"Light in room {room} turned on\"   def turn_off_light(room: str) -> str:     return f\"Light in room {room} turned off\"   def get_temperature(location: str) -> str:     # check the github repo for the code The SDK provides helpers to turn these functions into tools the assistant understands:  user_functions: Set[Callable[..., Any]] = {     turn_on_light,     turn_off_light,     get_temperature } functions = FunctionTool(user_functions) toolset = ToolSet() toolset.add(functions) Now we need to add the built-in code interpreter:  code_interpreter = CodeInterpreterTool() toolset.add(code_interpreter) Now we have a toolset with three custom functions and the code interpreter. This toolset is given to the agent via the toolset parameter.  Now that we have an agent, we need to provide a way to create a thread and add messages to the thread.  Creating a thread We are creating an API so we will create and endpoint to create a thread:  @app.post(\"/threads\") def create_thread() -> Dict[str, str]:     thread = project_client.agents.create_thread()     return {\"thread_id\": thread.id} As discussed earlier, a thread is created as a separate entity. It is not associated with the agent when you create it. When we later add a message, the thread will be associated with the agent that should process the message.  Working with messages Next, we will provide an endpoint that accepts a thread id and a message you want to add to it:  @app.post(\"/threads/{thread_id}/messages\") def send_message(thread_id: str, request: MessageRequest):     created_msg = project_client.agents.create_message(         thread_id=thread_id,         role=\"user\",         content=request.message  # Now accessing message from the request model     )     run = project_client.agents.create_and_process_run(         thread_id=thread_id,         assistant_id=agent.id     )     if run.status == \"failed\":         return {\"error\": run.last_error or \"Unknown error\"}       messages = project_client.agents.list_messages(thread_id=thread_id)     last_msg = messages.get_last_message_by_sender(\"assistant\")          last_msg_text = last_msg.text_messages[0].text.value if last_msg.text_messages else None     last_msg_image = last_msg.image_contents[0].image_file if last_msg.image_contents else None          last_msg_image_b64 = None     if last_msg_image:         file_stream = project_client.agents.get_file_content(file_id=last_msg_image.file_id)         base64_encoder = base64.b64encode         byte_chunks = b\"\".join(file_stream)  # Concatenate all bytes from the iterator.         last_msg_image_b64 = base64_encoder(byte_chunks).decode(\"utf-8\")              return {\"assistant_text\": last_msg_text,              \"assistant_image\": last_msg_image_b64} The code is pretty self-explanatory. In summary, here is what happens:  a message is created with the create_message method; the message is added to the specified thread_id as a user message the thread is run on the agent specified by the agent.id to know if the run is finished, polling is used; the create_and_process_run hides that complexity for you messages are retrieved from the thread but only the last assistant message is used we extract the text and image from the message if it is present when there is an image, we use get_file_content to retrieve the file content from the API; that functions returns an Iterator of bytes that are joined together and base64 encoded the message and image are returned Testing the API When we POST to the threads enpoint, this is the response:  {   \"thread_id\": \"thread_meYRMrkRtUiI1u0ZGH0z7PEN\" } We can use that id to post to the messages endpoint. For example in a .http file:  POST http://localhost:8000/threads/thread_meYRMrkRtUiI1u0ZGH0z7PEN/messages Content-Type: application/json   {     \"message\": \"Create a sample bar chart\" } The response to the above request should be something like below:  {   \"assistant_text\": \"Here is a sample bar chart displaying four categories (A to D) with their corresponding values. If you need any modifications or another type of chart, just let me know!\",   \"assistant_image\": \"iVBORw0KGgoAAAANSUhEUgAABpYAAARNCAYAAABYAnNeAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAB7CAAAewgFu0HU+AADWf0lEQ...\" } In this case, the model determined that the code interpreter should be used to create the sample bar chart. When you ask for something simpler, like the weather, you get the following response:  {   \"assistant_text\": \"The current temperature in London is 11.4Â°C. If you need more information or updates, feel free to ask!\",   \"assistant_image\": null } In this case, our custom weather function was used to answer. The assistant determines what tools should be used to provide an answer.  Integration in a web app The GitHub repository contains a sample UI to try the API:   Sample UI and a chat combining weather and plotting Beautiful, is it not? ðŸ˜‚  Conclusion The Azure AI Agent service makes it relatively easy to create an agent that has access to knowledge and tools. The assistant decides on its own how to use the knowledge and tools. However, you can steer the assistant via its instructions and influence how the assistant behaves.  The SDK makes it easy to add your own custom functions as tools, next to the built-in tools that it supports. Soon, there will be an Agent Service user interface in Azure AI Foundry. You will be able to create agents in code that reference the agents you have built in Foundry.  To try it for yourself, use the code in the GitHub repo. Note that the code is demo code with limited error handling. Itâ€™s merely meant to demonstrate first steps.  Enjoy and let me know what you build with it! ðŸ˜‰"
      },
      "output": {
        "headline": "\"Azure AI Agents: Build Intelligent Bots with Ease Using Foundry SDK\""
      },
      "metrics": null,
      "request": null,
      "parent_run_id": "1e3d52e8-08f4-4fe5-87ba-392596966feb",
      "root_run_id": "1e3d52e8-08f4-4fe5-87ba-392596966feb",
      "source_run_id": null,
      "flow_id": "default_flow_id",
      "start_time": "2025-01-08T15:22:20.060599Z",
      "end_time": "2025-01-08T15:22:21.164708Z",
      "index": 0,
      "api_calls": [
        {
          "name": "flow",
          "node_name": "flow",
          "type": "Flow",
          "start_time": 1736346140.060599,
          "end_time": 1736346141.164708,
          "children": [
            {
              "name": "AzureOpenAI.chat",
              "type": "Function",
              "inputs": {
                "prompt": "\nsystem:\nYou are an expert copywriter skilled at creating engaging, concise, and relevant headlines. Your task is to generate a list of potential headlines for a given article. \nThe headlines should be designed to capture the reader's attention while accurately reflecting the content and tone of the article. Follow these guidelines:\n\nRelevance: Ensure the headline aligns with the main idea of the article and avoids being misleading.\nClarity: Use simple, clear, and impactful language that is easy to understand.\nEngagement: Incorporate elements like curiosity, emotional appeal, or urgency to make the headline compelling.\nLength: Keep the headline concise (typically under 70 characters, but adapt as necessary for the context).\nTone and Style: Match the tone of the article (e.g., formal, casual, professional, playful).\n\nExamples of Effective Headlines:\n\"10 Simple Ways to Save Money on Everyday Expenses\"\n\"Revolutionizing Tech: How AI is Shaping the Future\"\n\"The Secrets Behind a Healthy Work-Life Balance\"\n\nuser:\nWrite a good  headline for the article below. Only output the title on one line.\n\n{{ content }}\n",
                "deployment_name": "gpt-4o",
                "content": "Azure AI Agents Service simplifies building intelligent agents by combining advanced AI models, tools, and technology from Microsoft, OpenAI, and partners like Meta and Cohere. It enables integration with knowledge sources such as Bing, SharePoint, and Azure AI Search, and lets agents perform actions across Microsoft and third-party applications using Logic Apps, Azure Functions, and Code Interpreter. With Azure AI Foundry, you get an intuitive agent-building experience, backed by enterprise-grade features like customizable storage, private networking, secure authentication, and detailed observability through OpenTelemetry.  At the time of this writing (December 2024), Azure AI Foundry did not provide a user interface yet to create these agents in the portal. In this post, we will use the Azure AI Foundry SDK to create the agent from code.  You can find the code in this repository: https://github.com/gbaeke/agent_service/tree/main/agentui  How does it work? The agent service uses the same wire protocol as the Azure OpenAI Assistants API. The Assistants API was developed as an alternative to the chat completions API. The big difference is that the Assistants API is stateful: your interactions with the AI model are saved as messages on a thread. You simply add messages to the thread for the model to respond.  For more information, check this video:   To get started, you need three things:  An agent: the agent uses a model and instructions about how it should behave. In addition, you add knowledge sources and tools. Knowledge sources can be files you upload to the agent or existing sources such as files on SharePoint. Tools can be built-in tools like code interpreter or custom tools like any API or custom functions that you write. A thread: threads receive messages from users and the assistant (the model) responds with assistant messages. In a chat application, each of the userâ€™s conversations can be a thread. Note that threads are created, independent of an agent. The thread is associated with the agent when you add a message. Messages: you add messages to a thread and check the thread for new messages. Messages can contain both text and images. For example, if you use the code interpreter tool and you asked for a chart, the chart will be created and handed to you as a file id. To render the chart, you would need to download it first based on its id. Creating the agent Before we create the agent, we need to connect to our Azure AI Foundry project. To do that (and more), we need the following imports:  import os from azure.ai.projects import AIProjectClient from azure.ai.projects.models import CodeInterpreterTool from azure.identity import DefaultAzureCredential from fastapi import FastAPI from typing import Dict from azure.ai.projects.models import FunctionTool, ToolSet from typing import Any, Callable, Set, Dict from fastapi.middleware.cors import CORSMiddleware from pydantic import BaseModel import requests import base64 We will use the AIProjectClient to get a reference to an Azure AI Foundry project. We do that with the following code:  # Set up credentials and project client credential = DefaultAzureCredential() conn_str = os.environ[\"PROJECT_CONNECTION_STRING\"] project_client = AIProjectClient.from_connection_string(     credential=credential, conn_str=conn_str ) Note that we authenticate with Entra ID. On your local machine, ensure you are logged on via the Azure CLI with az login. Your account needs at least AI Developer access to the Foundry project.  You also need the connection string to your project. The code requires it in the PROJECT_CONNECTION_STRING environment variable. You can find the connection string in Azure AI Foundry:   AI Foundry project connection string We can now create the agent with the following code:  agent = project_client.agents.create_agent(     model=\"gpt-4o-mini\",     name=\"my-agent\",     instructions=\"You are helpful agent with functions to turn on/off light and get temperature in a location. If location is not specified, ask the user.\",     toolset=toolset ) Above, the agent uses gpt-4o-mini. You need to ensure that model is deployed in your Azure AI Foundry Hub. In our example, we also provide the assistant with tools. We will not provide it with knowledge.  Whatâ€™s inside the toolset?  built-in code interpreter tool: provides a way for the model to write Python code, execute it and provide the result back to the model; the result can be text and/or images. custom tools: in our case, custom Python functions to turn on/off lights and look up weather information in a location. There are other tool types that we will not discuss in this post.  Adding tools Letâ€™s look at adding our own custom functions first. In the code, three functions are used as tools:  def turn_on_light(room: str) -> str:     return f\"Light in room {room} turned on\"   def turn_off_light(room: str) -> str:     return f\"Light in room {room} turned off\"   def get_temperature(location: str) -> str:     # check the github repo for the code The SDK provides helpers to turn these functions into tools the assistant understands:  user_functions: Set[Callable[..., Any]] = {     turn_on_light,     turn_off_light,     get_temperature } functions = FunctionTool(user_functions) toolset = ToolSet() toolset.add(functions) Now we need to add the built-in code interpreter:  code_interpreter = CodeInterpreterTool() toolset.add(code_interpreter) Now we have a toolset with three custom functions and the code interpreter. This toolset is given to the agent via the toolset parameter.  Now that we have an agent, we need to provide a way to create a thread and add messages to the thread.  Creating a thread We are creating an API so we will create and endpoint to create a thread:  @app.post(\"/threads\") def create_thread() -> Dict[str, str]:     thread = project_client.agents.create_thread()     return {\"thread_id\": thread.id} As discussed earlier, a thread is created as a separate entity. It is not associated with the agent when you create it. When we later add a message, the thread will be associated with the agent that should process the message.  Working with messages Next, we will provide an endpoint that accepts a thread id and a message you want to add to it:  @app.post(\"/threads/{thread_id}/messages\") def send_message(thread_id: str, request: MessageRequest):     created_msg = project_client.agents.create_message(         thread_id=thread_id,         role=\"user\",         content=request.message  # Now accessing message from the request model     )     run = project_client.agents.create_and_process_run(         thread_id=thread_id,         assistant_id=agent.id     )     if run.status == \"failed\":         return {\"error\": run.last_error or \"Unknown error\"}       messages = project_client.agents.list_messages(thread_id=thread_id)     last_msg = messages.get_last_message_by_sender(\"assistant\")          last_msg_text = last_msg.text_messages[0].text.value if last_msg.text_messages else None     last_msg_image = last_msg.image_contents[0].image_file if last_msg.image_contents else None          last_msg_image_b64 = None     if last_msg_image:         file_stream = project_client.agents.get_file_content(file_id=last_msg_image.file_id)         base64_encoder = base64.b64encode         byte_chunks = b\"\".join(file_stream)  # Concatenate all bytes from the iterator.         last_msg_image_b64 = base64_encoder(byte_chunks).decode(\"utf-8\")              return {\"assistant_text\": last_msg_text,              \"assistant_image\": last_msg_image_b64} The code is pretty self-explanatory. In summary, here is what happens:  a message is created with the create_message method; the message is added to the specified thread_id as a user message the thread is run on the agent specified by the agent.id to know if the run is finished, polling is used; the create_and_process_run hides that complexity for you messages are retrieved from the thread but only the last assistant message is used we extract the text and image from the message if it is present when there is an image, we use get_file_content to retrieve the file content from the API; that functions returns an Iterator of bytes that are joined together and base64 encoded the message and image are returned Testing the API When we POST to the threads enpoint, this is the response:  {   \"thread_id\": \"thread_meYRMrkRtUiI1u0ZGH0z7PEN\" } We can use that id to post to the messages endpoint. For example in a .http file:  POST http://localhost:8000/threads/thread_meYRMrkRtUiI1u0ZGH0z7PEN/messages Content-Type: application/json   {     \"message\": \"Create a sample bar chart\" } The response to the above request should be something like below:  {   \"assistant_text\": \"Here is a sample bar chart displaying four categories (A to D) with their corresponding values. If you need any modifications or another type of chart, just let me know!\",   \"assistant_image\": \"iVBORw0KGgoAAAANSUhEUgAABpYAAARNCAYAAABYAnNeAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAB7CAAAewgFu0HU+AADWf0lEQ...\" } In this case, the model determined that the code interpreter should be used to create the sample bar chart. When you ask for something simpler, like the weather, you get the following response:  {   \"assistant_text\": \"The current temperature in London is 11.4Â°C. If you need more information or updates, feel free to ask!\",   \"assistant_image\": null } In this case, our custom weather function was used to answer. The assistant determines what tools should be used to provide an answer.  Integration in a web app The GitHub repository contains a sample UI to try the API:   Sample UI and a chat combining weather and plotting Beautiful, is it not? ðŸ˜‚  Conclusion The Azure AI Agent service makes it relatively easy to create an agent that has access to knowledge and tools. The assistant decides on its own how to use the knowledge and tools. However, you can steer the assistant via its instructions and influence how the assistant behaves.  The SDK makes it easy to add your own custom functions as tools, next to the built-in tools that it supports. Soon, there will be an Agent Service user interface in Azure AI Foundry. You will be able to create agents in code that reference the agents you have built in Foundry.  To try it for yourself, use the code in the GitHub repo. Note that the code is demo code with limited error handling. Itâ€™s merely meant to demonstrate first steps.  Enjoy and let me know what you build with it! ðŸ˜‰",
                "_inputs_to_escape": [
                  "content"
                ],
                "stream": false
              },
              "output": "\"Azure AI Agents: Build Intelligent Bots with Ease Using Foundry SDK\"",
              "start_time": 1736346140.061497,
              "end_time": 1736346141.163268,
              "error": null,
              "children": [
                {
                  "name": "openai_chat",
                  "type": "LLM",
                  "inputs": {
                    "model": "gpt-4o",
                    "messages": [
                      {
                        "role": "system",
                        "content": "You are an expert copywriter skilled at creating engaging, concise, and relevant headlines. Your task is to generate a list of potential headlines for a given article. \nThe headlines should be designed to capture the reader's attention while accurately reflecting the content and tone of the article. Follow these guidelines:\n\nRelevance: Ensure the headline aligns with the main idea of the article and avoids being misleading.\nClarity: Use simple, clear, and impactful language that is easy to understand.\nEngagement: Incorporate elements like curiosity, emotional appeal, or urgency to make the headline compelling.\nLength: Keep the headline concise (typically under 70 characters, but adapt as necessary for the context).\nTone and Style: Match the tone of the article (e.g., formal, casual, professional, playful).\n\nExamples of Effective Headlines:\n\"10 Simple Ways to Save Money on Everyday Expenses\"\n\"Revolutionizing Tech: How AI is Shaping the Future\"\n\"The Secrets Behind a Healthy Work-Life Balance\""
                      },
                      {
                        "role": "user",
                        "content": "Write a good  headline for the article below. Only output the title on one line.\n\nAzure AI Agents Service simplifies building intelligent agents by combining advanced AI models, tools, and technology from Microsoft, OpenAI, and partners like Meta and Cohere. It enables integration with knowledge sources such as Bing, SharePoint, and Azure AI Search, and lets agents perform actions across Microsoft and third-party applications using Logic Apps, Azure Functions, and Code Interpreter. With Azure AI Foundry, you get an intuitive agent-building experience, backed by enterprise-grade features like customizable storage, private networking, secure authentication, and detailed observability through OpenTelemetry.  At the time of this writing (December 2024), Azure AI Foundry did not provide a user interface yet to create these agents in the portal. In this post, we will use the Azure AI Foundry SDK to create the agent from code.  You can find the code in this repository: https://github.com/gbaeke/agent_service/tree/main/agentui  How does it work? The agent service uses the same wire protocol as the Azure OpenAI Assistants API. The Assistants API was developed as an alternative to the chat completions API. The big difference is that the Assistants API is stateful: your interactions with the AI model are saved as messages on a thread. You simply add messages to the thread for the model to respond.  For more information, check this video:   To get started, you need three things:  An agent: the agent uses a model and instructions about how it should behave. In addition, you add knowledge sources and tools. Knowledge sources can be files you upload to the agent or existing sources such as files on SharePoint. Tools can be built-in tools like code interpreter or custom tools like any API or custom functions that you write. A thread: threads receive messages from users and the assistant (the model) responds with assistant messages. In a chat application, each of the userâ€™s conversations can be a thread. Note that threads are created, independent of an agent. The thread is associated with the agent when you add a message. Messages: you add messages to a thread and check the thread for new messages. Messages can contain both text and images. For example, if you use the code interpreter tool and you asked for a chart, the chart will be created and handed to you as a file id. To render the chart, you would need to download it first based on its id. Creating the agent Before we create the agent, we need to connect to our Azure AI Foundry project. To do that (and more), we need the following imports:  import os from azure.ai.projects import AIProjectClient from azure.ai.projects.models import CodeInterpreterTool from azure.identity import DefaultAzureCredential from fastapi import FastAPI from typing import Dict from azure.ai.projects.models import FunctionTool, ToolSet from typing import Any, Callable, Set, Dict from fastapi.middleware.cors import CORSMiddleware from pydantic import BaseModel import requests import base64 We will use the AIProjectClient to get a reference to an Azure AI Foundry project. We do that with the following code:  # Set up credentials and project client credential = DefaultAzureCredential() conn_str = os.environ[\"PROJECT_CONNECTION_STRING\"] project_client = AIProjectClient.from_connection_string(     credential=credential, conn_str=conn_str ) Note that we authenticate with Entra ID. On your local machine, ensure you are logged on via the Azure CLI with az login. Your account needs at least AI Developer access to the Foundry project.  You also need the connection string to your project. The code requires it in the PROJECT_CONNECTION_STRING environment variable. You can find the connection string in Azure AI Foundry:   AI Foundry project connection string We can now create the agent with the following code:  agent = project_client.agents.create_agent(     model=\"gpt-4o-mini\",     name=\"my-agent\",     instructions=\"You are helpful agent with functions to turn on/off light and get temperature in a location. If location is not specified, ask the user.\",     toolset=toolset ) Above, the agent uses gpt-4o-mini. You need to ensure that model is deployed in your Azure AI Foundry Hub. In our example, we also provide the assistant with tools. We will not provide it with knowledge.  Whatâ€™s inside the toolset?  built-in code interpreter tool: provides a way for the model to write Python code, execute it and provide the result back to the model; the result can be text and/or images. custom tools: in our case, custom Python functions to turn on/off lights and look up weather information in a location. There are other tool types that we will not discuss in this post.  Adding tools Letâ€™s look at adding our own custom functions first. In the code, three functions are used as tools:  def turn_on_light(room: str) -> str:     return f\"Light in room {room} turned on\"   def turn_off_light(room: str) -> str:     return f\"Light in room {room} turned off\"   def get_temperature(location: str) -> str:     # check the github repo for the code The SDK provides helpers to turn these functions into tools the assistant understands:  user_functions: Set[Callable[..., Any]] = {     turn_on_light,     turn_off_light,     get_temperature } functions = FunctionTool(user_functions) toolset = ToolSet() toolset.add(functions) Now we need to add the built-in code interpreter:  code_interpreter = CodeInterpreterTool() toolset.add(code_interpreter) Now we have a toolset with three custom functions and the code interpreter. This toolset is given to the agent via the toolset parameter.  Now that we have an agent, we need to provide a way to create a thread and add messages to the thread.  Creating a thread We are creating an API so we will create and endpoint to create a thread:  @app.post(\"/threads\") def create_thread() -> Dict[str, str]:     thread = project_client.agents.create_thread()     return {\"thread_id\": thread.id} As discussed earlier, a thread is created as a separate entity. It is not associated with the agent when you create it. When we later add a message, the thread will be associated with the agent that should process the message.  Working with messages Next, we will provide an endpoint that accepts a thread id and a message you want to add to it:  @app.post(\"/threads/{thread_id}/messages\") def send_message(thread_id: str, request: MessageRequest):     created_msg = project_client.agents.create_message(         thread_id=thread_id,         role=\"user\",         content=request.message  # Now accessing message from the request model     )     run = project_client.agents.create_and_process_run(         thread_id=thread_id,         assistant_id=agent.id     )     if run.status == \"failed\":         return {\"error\": run.last_error or \"Unknown error\"}       messages = project_client.agents.list_messages(thread_id=thread_id)     last_msg = messages.get_last_message_by_sender(\"assistant\")          last_msg_text = last_msg.text_messages[0].text.value if last_msg.text_messages else None     last_msg_image = last_msg.image_contents[0].image_file if last_msg.image_contents else None          last_msg_image_b64 = None     if last_msg_image:         file_stream = project_client.agents.get_file_content(file_id=last_msg_image.file_id)         base64_encoder = base64.b64encode         byte_chunks = b\"\".join(file_stream)  # Concatenate all bytes from the iterator.         last_msg_image_b64 = base64_encoder(byte_chunks).decode(\"utf-8\")              return {\"assistant_text\": last_msg_text,              \"assistant_image\": last_msg_image_b64} The code is pretty self-explanatory. In summary, here is what happens:  a message is created with the create_message method; the message is added to the specified thread_id as a user message the thread is run on the agent specified by the agent.id to know if the run is finished, polling is used; the create_and_process_run hides that complexity for you messages are retrieved from the thread but only the last assistant message is used we extract the text and image from the message if it is present when there is an image, we use get_file_content to retrieve the file content from the API; that functions returns an Iterator of bytes that are joined together and base64 encoded the message and image are returned Testing the API When we POST to the threads enpoint, this is the response:  {   \"thread_id\": \"thread_meYRMrkRtUiI1u0ZGH0z7PEN\" } We can use that id to post to the messages endpoint. For example in a .http file:  POST http://localhost:8000/threads/thread_meYRMrkRtUiI1u0ZGH0z7PEN/messages Content-Type: application/json   {     \"message\": \"Create a sample bar chart\" } The response to the above request should be something like below:  {   \"assistant_text\": \"Here is a sample bar chart displaying four categories (A to D) with their corresponding values. If you need any modifications or another type of chart, just let me know!\",   \"assistant_image\": \"iVBORw0KGgoAAAANSUhEUgAABpYAAARNCAYAAABYAnNeAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAB7CAAAewgFu0HU+AADWf0lEQ...\" } In this case, the model determined that the code interpreter should be used to create the sample bar chart. When you ask for something simpler, like the weather, you get the following response:  {   \"assistant_text\": \"The current temperature in London is 11.4Â°C. If you need more information or updates, feel free to ask!\",   \"assistant_image\": null } In this case, our custom weather function was used to answer. The assistant determines what tools should be used to provide an answer.  Integration in a web app The GitHub repository contains a sample UI to try the API:   Sample UI and a chat combining weather and plotting Beautiful, is it not? ðŸ˜‚  Conclusion The Azure AI Agent service makes it relatively easy to create an agent that has access to knowledge and tools. The assistant decides on its own how to use the knowledge and tools. However, you can steer the assistant via its instructions and influence how the assistant behaves.  The SDK makes it easy to add your own custom functions as tools, next to the built-in tools that it supports. Soon, there will be an Agent Service user interface in Azure AI Foundry. You will be able to create agents in code that reference the agents you have built in Foundry.  To try it for yourself, use the code in the GitHub repo. Note that the code is demo code with limited error handling. Itâ€™s merely meant to demonstrate first steps.  Enjoy and let me know what you build with it! ðŸ˜‰"
                      }
                    ],
                    "temperature": 1.0,
                    "top_p": 1.0,
                    "n": 1,
                    "stream": false,
                    "presence_penalty": 0.0,
                    "frequency_penalty": 0.0,
                    "user": ""
                  },
                  "output": {
                    "id": "chatcmpl-AnSAuKhERHNt0o6UwxPhqwaMh1a0Y",
                    "choices": [
                      {
                        "finish_reason": "stop",
                        "index": 0,
                        "logprobs": null,
                        "message": {
                          "content": "\"Azure AI Agents: Build Intelligent Bots with Ease Using Foundry SDK\"",
                          "refusal": null,
                          "role": "assistant",
                          "audio": null,
                          "function_call": null,
                          "tool_calls": null
                        },
                        "content_filter_results": {
                          "hate": {
                            "filtered": false,
                            "severity": "safe"
                          },
                          "self_harm": {
                            "filtered": false,
                            "severity": "safe"
                          },
                          "sexual": {
                            "filtered": false,
                            "severity": "safe"
                          },
                          "violence": {
                            "filtered": false,
                            "severity": "safe"
                          }
                        }
                      }
                    ],
                    "created": 1736349740,
                    "model": "gpt-4o-2024-08-06",
                    "object": "chat.completion",
                    "service_tier": null,
                    "system_fingerprint": "fp_4e924a4b48",
                    "usage": {
                      "completion_tokens": 15,
                      "prompt_tokens": 2565,
                      "total_tokens": 2580,
                      "completion_tokens_details": null,
                      "prompt_tokens_details": null
                    },
                    "prompt_filter_results": [
                      {
                        "prompt_index": 0,
                        "content_filter_results": {
                          "hate": {
                            "filtered": false,
                            "severity": "safe"
                          },
                          "jailbreak": {
                            "filtered": false,
                            "detected": false
                          },
                          "self_harm": {
                            "filtered": false,
                            "severity": "safe"
                          },
                          "sexual": {
                            "filtered": false,
                            "severity": "safe"
                          },
                          "violence": {
                            "filtered": false,
                            "severity": "safe"
                          }
                        }
                      }
                    ]
                  },
                  "start_time": 1736346140.06327,
                  "end_time": 1736346141.162999,
                  "error": null,
                  "children": [],
                  "node_name": null,
                  "parent_id": "28403cba-06b1-475d-9c4e-01f5496c213a",
                  "id": "2487bc57-a0b6-442b-96ed-f8554add290a",
                  "function": "openai.resources.chat.completions.Completions.create",
                  "system_metrics": {
                    "completion_tokens": 15,
                    "prompt_tokens": 2565,
                    "total_tokens": 2580
                  }
                }
              ],
              "node_name": "generate_title",
              "parent_id": "",
              "id": "28403cba-06b1-475d-9c4e-01f5496c213a",
              "function": "AzureOpenAI.chat",
              "system_metrics": {
                "completion_tokens": 15,
                "prompt_tokens": 2565,
                "total_tokens": 2580
              }
            }
          ],
          "system_metrics": {
            "duration": 1.104109,
            "prompt_tokens": 2565,
            "completion_tokens": 15,
            "total_tokens": 2580
          },
          "inputs": {
            "content": "Azure AI Agents Service simplifies building intelligent agents by combining advanced AI models, tools, and technology from Microsoft, OpenAI, and partners like Meta and Cohere. It enables integration with knowledge sources such as Bing, SharePoint, and Azure AI Search, and lets agents perform actions across Microsoft and third-party applications using Logic Apps, Azure Functions, and Code Interpreter. With Azure AI Foundry, you get an intuitive agent-building experience, backed by enterprise-grade features like customizable storage, private networking, secure authentication, and detailed observability through OpenTelemetry.  At the time of this writing (December 2024), Azure AI Foundry did not provide a user interface yet to create these agents in the portal. In this post, we will use the Azure AI Foundry SDK to create the agent from code.  You can find the code in this repository: https://github.com/gbaeke/agent_service/tree/main/agentui  How does it work? The agent service uses the same wire protocol as the Azure OpenAI Assistants API. The Assistants API was developed as an alternative to the chat completions API. The big difference is that the Assistants API is stateful: your interactions with the AI model are saved as messages on a thread. You simply add messages to the thread for the model to respond.  For more information, check this video:   To get started, you need three things:  An agent: the agent uses a model and instructions about how it should behave. In addition, you add knowledge sources and tools. Knowledge sources can be files you upload to the agent or existing sources such as files on SharePoint. Tools can be built-in tools like code interpreter or custom tools like any API or custom functions that you write. A thread: threads receive messages from users and the assistant (the model) responds with assistant messages. In a chat application, each of the userâ€™s conversations can be a thread. Note that threads are created, independent of an agent. The thread is associated with the agent when you add a message. Messages: you add messages to a thread and check the thread for new messages. Messages can contain both text and images. For example, if you use the code interpreter tool and you asked for a chart, the chart will be created and handed to you as a file id. To render the chart, you would need to download it first based on its id. Creating the agent Before we create the agent, we need to connect to our Azure AI Foundry project. To do that (and more), we need the following imports:  import os from azure.ai.projects import AIProjectClient from azure.ai.projects.models import CodeInterpreterTool from azure.identity import DefaultAzureCredential from fastapi import FastAPI from typing import Dict from azure.ai.projects.models import FunctionTool, ToolSet from typing import Any, Callable, Set, Dict from fastapi.middleware.cors import CORSMiddleware from pydantic import BaseModel import requests import base64 We will use the AIProjectClient to get a reference to an Azure AI Foundry project. We do that with the following code:  # Set up credentials and project client credential = DefaultAzureCredential() conn_str = os.environ[\"PROJECT_CONNECTION_STRING\"] project_client = AIProjectClient.from_connection_string(     credential=credential, conn_str=conn_str ) Note that we authenticate with Entra ID. On your local machine, ensure you are logged on via the Azure CLI with az login. Your account needs at least AI Developer access to the Foundry project.  You also need the connection string to your project. The code requires it in the PROJECT_CONNECTION_STRING environment variable. You can find the connection string in Azure AI Foundry:   AI Foundry project connection string We can now create the agent with the following code:  agent = project_client.agents.create_agent(     model=\"gpt-4o-mini\",     name=\"my-agent\",     instructions=\"You are helpful agent with functions to turn on/off light and get temperature in a location. If location is not specified, ask the user.\",     toolset=toolset ) Above, the agent uses gpt-4o-mini. You need to ensure that model is deployed in your Azure AI Foundry Hub. In our example, we also provide the assistant with tools. We will not provide it with knowledge.  Whatâ€™s inside the toolset?  built-in code interpreter tool: provides a way for the model to write Python code, execute it and provide the result back to the model; the result can be text and/or images. custom tools: in our case, custom Python functions to turn on/off lights and look up weather information in a location. There are other tool types that we will not discuss in this post.  Adding tools Letâ€™s look at adding our own custom functions first. In the code, three functions are used as tools:  def turn_on_light(room: str) -> str:     return f\"Light in room {room} turned on\"   def turn_off_light(room: str) -> str:     return f\"Light in room {room} turned off\"   def get_temperature(location: str) -> str:     # check the github repo for the code The SDK provides helpers to turn these functions into tools the assistant understands:  user_functions: Set[Callable[..., Any]] = {     turn_on_light,     turn_off_light,     get_temperature } functions = FunctionTool(user_functions) toolset = ToolSet() toolset.add(functions) Now we need to add the built-in code interpreter:  code_interpreter = CodeInterpreterTool() toolset.add(code_interpreter) Now we have a toolset with three custom functions and the code interpreter. This toolset is given to the agent via the toolset parameter.  Now that we have an agent, we need to provide a way to create a thread and add messages to the thread.  Creating a thread We are creating an API so we will create and endpoint to create a thread:  @app.post(\"/threads\") def create_thread() -> Dict[str, str]:     thread = project_client.agents.create_thread()     return {\"thread_id\": thread.id} As discussed earlier, a thread is created as a separate entity. It is not associated with the agent when you create it. When we later add a message, the thread will be associated with the agent that should process the message.  Working with messages Next, we will provide an endpoint that accepts a thread id and a message you want to add to it:  @app.post(\"/threads/{thread_id}/messages\") def send_message(thread_id: str, request: MessageRequest):     created_msg = project_client.agents.create_message(         thread_id=thread_id,         role=\"user\",         content=request.message  # Now accessing message from the request model     )     run = project_client.agents.create_and_process_run(         thread_id=thread_id,         assistant_id=agent.id     )     if run.status == \"failed\":         return {\"error\": run.last_error or \"Unknown error\"}       messages = project_client.agents.list_messages(thread_id=thread_id)     last_msg = messages.get_last_message_by_sender(\"assistant\")          last_msg_text = last_msg.text_messages[0].text.value if last_msg.text_messages else None     last_msg_image = last_msg.image_contents[0].image_file if last_msg.image_contents else None          last_msg_image_b64 = None     if last_msg_image:         file_stream = project_client.agents.get_file_content(file_id=last_msg_image.file_id)         base64_encoder = base64.b64encode         byte_chunks = b\"\".join(file_stream)  # Concatenate all bytes from the iterator.         last_msg_image_b64 = base64_encoder(byte_chunks).decode(\"utf-8\")              return {\"assistant_text\": last_msg_text,              \"assistant_image\": last_msg_image_b64} The code is pretty self-explanatory. In summary, here is what happens:  a message is created with the create_message method; the message is added to the specified thread_id as a user message the thread is run on the agent specified by the agent.id to know if the run is finished, polling is used; the create_and_process_run hides that complexity for you messages are retrieved from the thread but only the last assistant message is used we extract the text and image from the message if it is present when there is an image, we use get_file_content to retrieve the file content from the API; that functions returns an Iterator of bytes that are joined together and base64 encoded the message and image are returned Testing the API When we POST to the threads enpoint, this is the response:  {   \"thread_id\": \"thread_meYRMrkRtUiI1u0ZGH0z7PEN\" } We can use that id to post to the messages endpoint. For example in a .http file:  POST http://localhost:8000/threads/thread_meYRMrkRtUiI1u0ZGH0z7PEN/messages Content-Type: application/json   {     \"message\": \"Create a sample bar chart\" } The response to the above request should be something like below:  {   \"assistant_text\": \"Here is a sample bar chart displaying four categories (A to D) with their corresponding values. If you need any modifications or another type of chart, just let me know!\",   \"assistant_image\": \"iVBORw0KGgoAAAANSUhEUgAABpYAAARNCAYAAABYAnNeAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAB7CAAAewgFu0HU+AADWf0lEQ...\" } In this case, the model determined that the code interpreter should be used to create the sample bar chart. When you ask for something simpler, like the weather, you get the following response:  {   \"assistant_text\": \"The current temperature in London is 11.4Â°C. If you need more information or updates, feel free to ask!\",   \"assistant_image\": null } In this case, our custom weather function was used to answer. The assistant determines what tools should be used to provide an answer.  Integration in a web app The GitHub repository contains a sample UI to try the API:   Sample UI and a chat combining weather and plotting Beautiful, is it not? ðŸ˜‚  Conclusion The Azure AI Agent service makes it relatively easy to create an agent that has access to knowledge and tools. The assistant decides on its own how to use the knowledge and tools. However, you can steer the assistant via its instructions and influence how the assistant behaves.  The SDK makes it easy to add your own custom functions as tools, next to the built-in tools that it supports. Soon, there will be an Agent Service user interface in Azure AI Foundry. You will be able to create agents in code that reference the agents you have built in Foundry.  To try it for yourself, use the code in the GitHub repo. Note that the code is demo code with limited error handling. Itâ€™s merely meant to demonstrate first steps.  Enjoy and let me know what you build with it! ðŸ˜‰"
          },
          "output": {
            "headline": "\"Azure AI Agents: Build Intelligent Bots with Ease Using Foundry SDK\""
          },
          "error": null
        }
      ],
      "name": "",
      "description": "",
      "tags": null,
      "system_metrics": {
        "duration": 1.104109,
        "prompt_tokens": 2565,
        "completion_tokens": 15,
        "total_tokens": 2580
      },
      "result": {
        "headline": "\"Azure AI Agents: Build Intelligent Bots with Ease Using Foundry SDK\""
      },
      "upload_metrics": false,
      "otel_trace_id": "0xd70a8b722d08607a433390919c75374c",
      "message_format": "basic"
    }
  ],
  "node_runs": [
    {
      "node": "generate_title",
      "flow_run_id": "1e3d52e8-08f4-4fe5-87ba-392596966feb",
      "run_id": "1e3d52e8-08f4-4fe5-87ba-392596966feb_generate_title_0",
      "status": "Completed",
      "inputs": {
        "deployment_name": "gpt-4o",
        "content": "Azure AI Agents Service simplifies building intelligent agents by combining advanced AI models, tools, and technology from Microsoft, OpenAI, and partners like Meta and Cohere. It enables integration with knowledge sources such as Bing, SharePoint, and Azure AI Search, and lets agents perform actions across Microsoft and third-party applications using Logic Apps, Azure Functions, and Code Interpreter. With Azure AI Foundry, you get an intuitive agent-building experience, backed by enterprise-grade features like customizable storage, private networking, secure authentication, and detailed observability through OpenTelemetry.  At the time of this writing (December 2024), Azure AI Foundry did not provide a user interface yet to create these agents in the portal. In this post, we will use the Azure AI Foundry SDK to create the agent from code.  You can find the code in this repository: https://github.com/gbaeke/agent_service/tree/main/agentui  How does it work? The agent service uses the same wire protocol as the Azure OpenAI Assistants API. The Assistants API was developed as an alternative to the chat completions API. The big difference is that the Assistants API is stateful: your interactions with the AI model are saved as messages on a thread. You simply add messages to the thread for the model to respond.  For more information, check this video:   To get started, you need three things:  An agent: the agent uses a model and instructions about how it should behave. In addition, you add knowledge sources and tools. Knowledge sources can be files you upload to the agent or existing sources such as files on SharePoint. Tools can be built-in tools like code interpreter or custom tools like any API or custom functions that you write. A thread: threads receive messages from users and the assistant (the model) responds with assistant messages. In a chat application, each of the userâ€™s conversations can be a thread. Note that threads are created, independent of an agent. The thread is associated with the agent when you add a message. Messages: you add messages to a thread and check the thread for new messages. Messages can contain both text and images. For example, if you use the code interpreter tool and you asked for a chart, the chart will be created and handed to you as a file id. To render the chart, you would need to download it first based on its id. Creating the agent Before we create the agent, we need to connect to our Azure AI Foundry project. To do that (and more), we need the following imports:  import os from azure.ai.projects import AIProjectClient from azure.ai.projects.models import CodeInterpreterTool from azure.identity import DefaultAzureCredential from fastapi import FastAPI from typing import Dict from azure.ai.projects.models import FunctionTool, ToolSet from typing import Any, Callable, Set, Dict from fastapi.middleware.cors import CORSMiddleware from pydantic import BaseModel import requests import base64 We will use the AIProjectClient to get a reference to an Azure AI Foundry project. We do that with the following code:  # Set up credentials and project client credential = DefaultAzureCredential() conn_str = os.environ[\"PROJECT_CONNECTION_STRING\"] project_client = AIProjectClient.from_connection_string(     credential=credential, conn_str=conn_str ) Note that we authenticate with Entra ID. On your local machine, ensure you are logged on via the Azure CLI with az login. Your account needs at least AI Developer access to the Foundry project.  You also need the connection string to your project. The code requires it in the PROJECT_CONNECTION_STRING environment variable. You can find the connection string in Azure AI Foundry:   AI Foundry project connection string We can now create the agent with the following code:  agent = project_client.agents.create_agent(     model=\"gpt-4o-mini\",     name=\"my-agent\",     instructions=\"You are helpful agent with functions to turn on/off light and get temperature in a location. If location is not specified, ask the user.\",     toolset=toolset ) Above, the agent uses gpt-4o-mini. You need to ensure that model is deployed in your Azure AI Foundry Hub. In our example, we also provide the assistant with tools. We will not provide it with knowledge.  Whatâ€™s inside the toolset?  built-in code interpreter tool: provides a way for the model to write Python code, execute it and provide the result back to the model; the result can be text and/or images. custom tools: in our case, custom Python functions to turn on/off lights and look up weather information in a location. There are other tool types that we will not discuss in this post.  Adding tools Letâ€™s look at adding our own custom functions first. In the code, three functions are used as tools:  def turn_on_light(room: str) -> str:     return f\"Light in room {room} turned on\"   def turn_off_light(room: str) -> str:     return f\"Light in room {room} turned off\"   def get_temperature(location: str) -> str:     # check the github repo for the code The SDK provides helpers to turn these functions into tools the assistant understands:  user_functions: Set[Callable[..., Any]] = {     turn_on_light,     turn_off_light,     get_temperature } functions = FunctionTool(user_functions) toolset = ToolSet() toolset.add(functions) Now we need to add the built-in code interpreter:  code_interpreter = CodeInterpreterTool() toolset.add(code_interpreter) Now we have a toolset with three custom functions and the code interpreter. This toolset is given to the agent via the toolset parameter.  Now that we have an agent, we need to provide a way to create a thread and add messages to the thread.  Creating a thread We are creating an API so we will create and endpoint to create a thread:  @app.post(\"/threads\") def create_thread() -> Dict[str, str]:     thread = project_client.agents.create_thread()     return {\"thread_id\": thread.id} As discussed earlier, a thread is created as a separate entity. It is not associated with the agent when you create it. When we later add a message, the thread will be associated with the agent that should process the message.  Working with messages Next, we will provide an endpoint that accepts a thread id and a message you want to add to it:  @app.post(\"/threads/{thread_id}/messages\") def send_message(thread_id: str, request: MessageRequest):     created_msg = project_client.agents.create_message(         thread_id=thread_id,         role=\"user\",         content=request.message  # Now accessing message from the request model     )     run = project_client.agents.create_and_process_run(         thread_id=thread_id,         assistant_id=agent.id     )     if run.status == \"failed\":         return {\"error\": run.last_error or \"Unknown error\"}       messages = project_client.agents.list_messages(thread_id=thread_id)     last_msg = messages.get_last_message_by_sender(\"assistant\")          last_msg_text = last_msg.text_messages[0].text.value if last_msg.text_messages else None     last_msg_image = last_msg.image_contents[0].image_file if last_msg.image_contents else None          last_msg_image_b64 = None     if last_msg_image:         file_stream = project_client.agents.get_file_content(file_id=last_msg_image.file_id)         base64_encoder = base64.b64encode         byte_chunks = b\"\".join(file_stream)  # Concatenate all bytes from the iterator.         last_msg_image_b64 = base64_encoder(byte_chunks).decode(\"utf-8\")              return {\"assistant_text\": last_msg_text,              \"assistant_image\": last_msg_image_b64} The code is pretty self-explanatory. In summary, here is what happens:  a message is created with the create_message method; the message is added to the specified thread_id as a user message the thread is run on the agent specified by the agent.id to know if the run is finished, polling is used; the create_and_process_run hides that complexity for you messages are retrieved from the thread but only the last assistant message is used we extract the text and image from the message if it is present when there is an image, we use get_file_content to retrieve the file content from the API; that functions returns an Iterator of bytes that are joined together and base64 encoded the message and image are returned Testing the API When we POST to the threads enpoint, this is the response:  {   \"thread_id\": \"thread_meYRMrkRtUiI1u0ZGH0z7PEN\" } We can use that id to post to the messages endpoint. For example in a .http file:  POST http://localhost:8000/threads/thread_meYRMrkRtUiI1u0ZGH0z7PEN/messages Content-Type: application/json   {     \"message\": \"Create a sample bar chart\" } The response to the above request should be something like below:  {   \"assistant_text\": \"Here is a sample bar chart displaying four categories (A to D) with their corresponding values. If you need any modifications or another type of chart, just let me know!\",   \"assistant_image\": \"iVBORw0KGgoAAAANSUhEUgAABpYAAARNCAYAAABYAnNeAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAB7CAAAewgFu0HU+AADWf0lEQ...\" } In this case, the model determined that the code interpreter should be used to create the sample bar chart. When you ask for something simpler, like the weather, you get the following response:  {   \"assistant_text\": \"The current temperature in London is 11.4Â°C. If you need more information or updates, feel free to ask!\",   \"assistant_image\": null } In this case, our custom weather function was used to answer. The assistant determines what tools should be used to provide an answer.  Integration in a web app The GitHub repository contains a sample UI to try the API:   Sample UI and a chat combining weather and plotting Beautiful, is it not? ðŸ˜‚  Conclusion The Azure AI Agent service makes it relatively easy to create an agent that has access to knowledge and tools. The assistant decides on its own how to use the knowledge and tools. However, you can steer the assistant via its instructions and influence how the assistant behaves.  The SDK makes it easy to add your own custom functions as tools, next to the built-in tools that it supports. Soon, there will be an Agent Service user interface in Azure AI Foundry. You will be able to create agents in code that reference the agents you have built in Foundry.  To try it for yourself, use the code in the GitHub repo. Note that the code is demo code with limited error handling. Itâ€™s merely meant to demonstrate first steps.  Enjoy and let me know what you build with it! ðŸ˜‰",
        "_inputs_to_escape": [
          "content"
        ]
      },
      "output": "\"Azure AI Agents: Build Intelligent Bots with Ease Using Foundry SDK\"",
      "metrics": null,
      "error": null,
      "parent_run_id": "1e3d52e8-08f4-4fe5-87ba-392596966feb_0",
      "start_time": "2025-01-08T15:22:20.061424Z",
      "end_time": "2025-01-08T15:22:21.164083Z",
      "index": 0,
      "api_calls": [
        {
          "name": "AzureOpenAI.chat",
          "type": "Function",
          "inputs": {
            "prompt": "\nsystem:\nYou are an expert copywriter skilled at creating engaging, concise, and relevant headlines. Your task is to generate a list of potential headlines for a given article. \nThe headlines should be designed to capture the reader's attention while accurately reflecting the content and tone of the article. Follow these guidelines:\n\nRelevance: Ensure the headline aligns with the main idea of the article and avoids being misleading.\nClarity: Use simple, clear, and impactful language that is easy to understand.\nEngagement: Incorporate elements like curiosity, emotional appeal, or urgency to make the headline compelling.\nLength: Keep the headline concise (typically under 70 characters, but adapt as necessary for the context).\nTone and Style: Match the tone of the article (e.g., formal, casual, professional, playful).\n\nExamples of Effective Headlines:\n\"10 Simple Ways to Save Money on Everyday Expenses\"\n\"Revolutionizing Tech: How AI is Shaping the Future\"\n\"The Secrets Behind a Healthy Work-Life Balance\"\n\nuser:\nWrite a good  headline for the article below. Only output the title on one line.\n\n{{ content }}\n",
            "deployment_name": "gpt-4o",
            "content": "Azure AI Agents Service simplifies building intelligent agents by combining advanced AI models, tools, and technology from Microsoft, OpenAI, and partners like Meta and Cohere. It enables integration with knowledge sources such as Bing, SharePoint, and Azure AI Search, and lets agents perform actions across Microsoft and third-party applications using Logic Apps, Azure Functions, and Code Interpreter. With Azure AI Foundry, you get an intuitive agent-building experience, backed by enterprise-grade features like customizable storage, private networking, secure authentication, and detailed observability through OpenTelemetry.  At the time of this writing (December 2024), Azure AI Foundry did not provide a user interface yet to create these agents in the portal. In this post, we will use the Azure AI Foundry SDK to create the agent from code.  You can find the code in this repository: https://github.com/gbaeke/agent_service/tree/main/agentui  How does it work? The agent service uses the same wire protocol as the Azure OpenAI Assistants API. The Assistants API was developed as an alternative to the chat completions API. The big difference is that the Assistants API is stateful: your interactions with the AI model are saved as messages on a thread. You simply add messages to the thread for the model to respond.  For more information, check this video:   To get started, you need three things:  An agent: the agent uses a model and instructions about how it should behave. In addition, you add knowledge sources and tools. Knowledge sources can be files you upload to the agent or existing sources such as files on SharePoint. Tools can be built-in tools like code interpreter or custom tools like any API or custom functions that you write. A thread: threads receive messages from users and the assistant (the model) responds with assistant messages. In a chat application, each of the userâ€™s conversations can be a thread. Note that threads are created, independent of an agent. The thread is associated with the agent when you add a message. Messages: you add messages to a thread and check the thread for new messages. Messages can contain both text and images. For example, if you use the code interpreter tool and you asked for a chart, the chart will be created and handed to you as a file id. To render the chart, you would need to download it first based on its id. Creating the agent Before we create the agent, we need to connect to our Azure AI Foundry project. To do that (and more), we need the following imports:  import os from azure.ai.projects import AIProjectClient from azure.ai.projects.models import CodeInterpreterTool from azure.identity import DefaultAzureCredential from fastapi import FastAPI from typing import Dict from azure.ai.projects.models import FunctionTool, ToolSet from typing import Any, Callable, Set, Dict from fastapi.middleware.cors import CORSMiddleware from pydantic import BaseModel import requests import base64 We will use the AIProjectClient to get a reference to an Azure AI Foundry project. We do that with the following code:  # Set up credentials and project client credential = DefaultAzureCredential() conn_str = os.environ[\"PROJECT_CONNECTION_STRING\"] project_client = AIProjectClient.from_connection_string(     credential=credential, conn_str=conn_str ) Note that we authenticate with Entra ID. On your local machine, ensure you are logged on via the Azure CLI with az login. Your account needs at least AI Developer access to the Foundry project.  You also need the connection string to your project. The code requires it in the PROJECT_CONNECTION_STRING environment variable. You can find the connection string in Azure AI Foundry:   AI Foundry project connection string We can now create the agent with the following code:  agent = project_client.agents.create_agent(     model=\"gpt-4o-mini\",     name=\"my-agent\",     instructions=\"You are helpful agent with functions to turn on/off light and get temperature in a location. If location is not specified, ask the user.\",     toolset=toolset ) Above, the agent uses gpt-4o-mini. You need to ensure that model is deployed in your Azure AI Foundry Hub. In our example, we also provide the assistant with tools. We will not provide it with knowledge.  Whatâ€™s inside the toolset?  built-in code interpreter tool: provides a way for the model to write Python code, execute it and provide the result back to the model; the result can be text and/or images. custom tools: in our case, custom Python functions to turn on/off lights and look up weather information in a location. There are other tool types that we will not discuss in this post.  Adding tools Letâ€™s look at adding our own custom functions first. In the code, three functions are used as tools:  def turn_on_light(room: str) -> str:     return f\"Light in room {room} turned on\"   def turn_off_light(room: str) -> str:     return f\"Light in room {room} turned off\"   def get_temperature(location: str) -> str:     # check the github repo for the code The SDK provides helpers to turn these functions into tools the assistant understands:  user_functions: Set[Callable[..., Any]] = {     turn_on_light,     turn_off_light,     get_temperature } functions = FunctionTool(user_functions) toolset = ToolSet() toolset.add(functions) Now we need to add the built-in code interpreter:  code_interpreter = CodeInterpreterTool() toolset.add(code_interpreter) Now we have a toolset with three custom functions and the code interpreter. This toolset is given to the agent via the toolset parameter.  Now that we have an agent, we need to provide a way to create a thread and add messages to the thread.  Creating a thread We are creating an API so we will create and endpoint to create a thread:  @app.post(\"/threads\") def create_thread() -> Dict[str, str]:     thread = project_client.agents.create_thread()     return {\"thread_id\": thread.id} As discussed earlier, a thread is created as a separate entity. It is not associated with the agent when you create it. When we later add a message, the thread will be associated with the agent that should process the message.  Working with messages Next, we will provide an endpoint that accepts a thread id and a message you want to add to it:  @app.post(\"/threads/{thread_id}/messages\") def send_message(thread_id: str, request: MessageRequest):     created_msg = project_client.agents.create_message(         thread_id=thread_id,         role=\"user\",         content=request.message  # Now accessing message from the request model     )     run = project_client.agents.create_and_process_run(         thread_id=thread_id,         assistant_id=agent.id     )     if run.status == \"failed\":         return {\"error\": run.last_error or \"Unknown error\"}       messages = project_client.agents.list_messages(thread_id=thread_id)     last_msg = messages.get_last_message_by_sender(\"assistant\")          last_msg_text = last_msg.text_messages[0].text.value if last_msg.text_messages else None     last_msg_image = last_msg.image_contents[0].image_file if last_msg.image_contents else None          last_msg_image_b64 = None     if last_msg_image:         file_stream = project_client.agents.get_file_content(file_id=last_msg_image.file_id)         base64_encoder = base64.b64encode         byte_chunks = b\"\".join(file_stream)  # Concatenate all bytes from the iterator.         last_msg_image_b64 = base64_encoder(byte_chunks).decode(\"utf-8\")              return {\"assistant_text\": last_msg_text,              \"assistant_image\": last_msg_image_b64} The code is pretty self-explanatory. In summary, here is what happens:  a message is created with the create_message method; the message is added to the specified thread_id as a user message the thread is run on the agent specified by the agent.id to know if the run is finished, polling is used; the create_and_process_run hides that complexity for you messages are retrieved from the thread but only the last assistant message is used we extract the text and image from the message if it is present when there is an image, we use get_file_content to retrieve the file content from the API; that functions returns an Iterator of bytes that are joined together and base64 encoded the message and image are returned Testing the API When we POST to the threads enpoint, this is the response:  {   \"thread_id\": \"thread_meYRMrkRtUiI1u0ZGH0z7PEN\" } We can use that id to post to the messages endpoint. For example in a .http file:  POST http://localhost:8000/threads/thread_meYRMrkRtUiI1u0ZGH0z7PEN/messages Content-Type: application/json   {     \"message\": \"Create a sample bar chart\" } The response to the above request should be something like below:  {   \"assistant_text\": \"Here is a sample bar chart displaying four categories (A to D) with their corresponding values. If you need any modifications or another type of chart, just let me know!\",   \"assistant_image\": \"iVBORw0KGgoAAAANSUhEUgAABpYAAARNCAYAAABYAnNeAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAB7CAAAewgFu0HU+AADWf0lEQ...\" } In this case, the model determined that the code interpreter should be used to create the sample bar chart. When you ask for something simpler, like the weather, you get the following response:  {   \"assistant_text\": \"The current temperature in London is 11.4Â°C. If you need more information or updates, feel free to ask!\",   \"assistant_image\": null } In this case, our custom weather function was used to answer. The assistant determines what tools should be used to provide an answer.  Integration in a web app The GitHub repository contains a sample UI to try the API:   Sample UI and a chat combining weather and plotting Beautiful, is it not? ðŸ˜‚  Conclusion The Azure AI Agent service makes it relatively easy to create an agent that has access to knowledge and tools. The assistant decides on its own how to use the knowledge and tools. However, you can steer the assistant via its instructions and influence how the assistant behaves.  The SDK makes it easy to add your own custom functions as tools, next to the built-in tools that it supports. Soon, there will be an Agent Service user interface in Azure AI Foundry. You will be able to create agents in code that reference the agents you have built in Foundry.  To try it for yourself, use the code in the GitHub repo. Note that the code is demo code with limited error handling. Itâ€™s merely meant to demonstrate first steps.  Enjoy and let me know what you build with it! ðŸ˜‰",
            "_inputs_to_escape": [
              "content"
            ],
            "stream": false
          },
          "output": "\"Azure AI Agents: Build Intelligent Bots with Ease Using Foundry SDK\"",
          "start_time": 1736346140.061497,
          "end_time": 1736346141.163268,
          "error": null,
          "children": [
            {
              "name": "openai_chat",
              "type": "LLM",
              "inputs": {
                "model": "gpt-4o",
                "messages": [
                  {
                    "role": "system",
                    "content": "You are an expert copywriter skilled at creating engaging, concise, and relevant headlines. Your task is to generate a list of potential headlines for a given article. \nThe headlines should be designed to capture the reader's attention while accurately reflecting the content and tone of the article. Follow these guidelines:\n\nRelevance: Ensure the headline aligns with the main idea of the article and avoids being misleading.\nClarity: Use simple, clear, and impactful language that is easy to understand.\nEngagement: Incorporate elements like curiosity, emotional appeal, or urgency to make the headline compelling.\nLength: Keep the headline concise (typically under 70 characters, but adapt as necessary for the context).\nTone and Style: Match the tone of the article (e.g., formal, casual, professional, playful).\n\nExamples of Effective Headlines:\n\"10 Simple Ways to Save Money on Everyday Expenses\"\n\"Revolutionizing Tech: How AI is Shaping the Future\"\n\"The Secrets Behind a Healthy Work-Life Balance\""
                  },
                  {
                    "role": "user",
                    "content": "Write a good  headline for the article below. Only output the title on one line.\n\nAzure AI Agents Service simplifies building intelligent agents by combining advanced AI models, tools, and technology from Microsoft, OpenAI, and partners like Meta and Cohere. It enables integration with knowledge sources such as Bing, SharePoint, and Azure AI Search, and lets agents perform actions across Microsoft and third-party applications using Logic Apps, Azure Functions, and Code Interpreter. With Azure AI Foundry, you get an intuitive agent-building experience, backed by enterprise-grade features like customizable storage, private networking, secure authentication, and detailed observability through OpenTelemetry.  At the time of this writing (December 2024), Azure AI Foundry did not provide a user interface yet to create these agents in the portal. In this post, we will use the Azure AI Foundry SDK to create the agent from code.  You can find the code in this repository: https://github.com/gbaeke/agent_service/tree/main/agentui  How does it work? The agent service uses the same wire protocol as the Azure OpenAI Assistants API. The Assistants API was developed as an alternative to the chat completions API. The big difference is that the Assistants API is stateful: your interactions with the AI model are saved as messages on a thread. You simply add messages to the thread for the model to respond.  For more information, check this video:   To get started, you need three things:  An agent: the agent uses a model and instructions about how it should behave. In addition, you add knowledge sources and tools. Knowledge sources can be files you upload to the agent or existing sources such as files on SharePoint. Tools can be built-in tools like code interpreter or custom tools like any API or custom functions that you write. A thread: threads receive messages from users and the assistant (the model) responds with assistant messages. In a chat application, each of the userâ€™s conversations can be a thread. Note that threads are created, independent of an agent. The thread is associated with the agent when you add a message. Messages: you add messages to a thread and check the thread for new messages. Messages can contain both text and images. For example, if you use the code interpreter tool and you asked for a chart, the chart will be created and handed to you as a file id. To render the chart, you would need to download it first based on its id. Creating the agent Before we create the agent, we need to connect to our Azure AI Foundry project. To do that (and more), we need the following imports:  import os from azure.ai.projects import AIProjectClient from azure.ai.projects.models import CodeInterpreterTool from azure.identity import DefaultAzureCredential from fastapi import FastAPI from typing import Dict from azure.ai.projects.models import FunctionTool, ToolSet from typing import Any, Callable, Set, Dict from fastapi.middleware.cors import CORSMiddleware from pydantic import BaseModel import requests import base64 We will use the AIProjectClient to get a reference to an Azure AI Foundry project. We do that with the following code:  # Set up credentials and project client credential = DefaultAzureCredential() conn_str = os.environ[\"PROJECT_CONNECTION_STRING\"] project_client = AIProjectClient.from_connection_string(     credential=credential, conn_str=conn_str ) Note that we authenticate with Entra ID. On your local machine, ensure you are logged on via the Azure CLI with az login. Your account needs at least AI Developer access to the Foundry project.  You also need the connection string to your project. The code requires it in the PROJECT_CONNECTION_STRING environment variable. You can find the connection string in Azure AI Foundry:   AI Foundry project connection string We can now create the agent with the following code:  agent = project_client.agents.create_agent(     model=\"gpt-4o-mini\",     name=\"my-agent\",     instructions=\"You are helpful agent with functions to turn on/off light and get temperature in a location. If location is not specified, ask the user.\",     toolset=toolset ) Above, the agent uses gpt-4o-mini. You need to ensure that model is deployed in your Azure AI Foundry Hub. In our example, we also provide the assistant with tools. We will not provide it with knowledge.  Whatâ€™s inside the toolset?  built-in code interpreter tool: provides a way for the model to write Python code, execute it and provide the result back to the model; the result can be text and/or images. custom tools: in our case, custom Python functions to turn on/off lights and look up weather information in a location. There are other tool types that we will not discuss in this post.  Adding tools Letâ€™s look at adding our own custom functions first. In the code, three functions are used as tools:  def turn_on_light(room: str) -> str:     return f\"Light in room {room} turned on\"   def turn_off_light(room: str) -> str:     return f\"Light in room {room} turned off\"   def get_temperature(location: str) -> str:     # check the github repo for the code The SDK provides helpers to turn these functions into tools the assistant understands:  user_functions: Set[Callable[..., Any]] = {     turn_on_light,     turn_off_light,     get_temperature } functions = FunctionTool(user_functions) toolset = ToolSet() toolset.add(functions) Now we need to add the built-in code interpreter:  code_interpreter = CodeInterpreterTool() toolset.add(code_interpreter) Now we have a toolset with three custom functions and the code interpreter. This toolset is given to the agent via the toolset parameter.  Now that we have an agent, we need to provide a way to create a thread and add messages to the thread.  Creating a thread We are creating an API so we will create and endpoint to create a thread:  @app.post(\"/threads\") def create_thread() -> Dict[str, str]:     thread = project_client.agents.create_thread()     return {\"thread_id\": thread.id} As discussed earlier, a thread is created as a separate entity. It is not associated with the agent when you create it. When we later add a message, the thread will be associated with the agent that should process the message.  Working with messages Next, we will provide an endpoint that accepts a thread id and a message you want to add to it:  @app.post(\"/threads/{thread_id}/messages\") def send_message(thread_id: str, request: MessageRequest):     created_msg = project_client.agents.create_message(         thread_id=thread_id,         role=\"user\",         content=request.message  # Now accessing message from the request model     )     run = project_client.agents.create_and_process_run(         thread_id=thread_id,         assistant_id=agent.id     )     if run.status == \"failed\":         return {\"error\": run.last_error or \"Unknown error\"}       messages = project_client.agents.list_messages(thread_id=thread_id)     last_msg = messages.get_last_message_by_sender(\"assistant\")          last_msg_text = last_msg.text_messages[0].text.value if last_msg.text_messages else None     last_msg_image = last_msg.image_contents[0].image_file if last_msg.image_contents else None          last_msg_image_b64 = None     if last_msg_image:         file_stream = project_client.agents.get_file_content(file_id=last_msg_image.file_id)         base64_encoder = base64.b64encode         byte_chunks = b\"\".join(file_stream)  # Concatenate all bytes from the iterator.         last_msg_image_b64 = base64_encoder(byte_chunks).decode(\"utf-8\")              return {\"assistant_text\": last_msg_text,              \"assistant_image\": last_msg_image_b64} The code is pretty self-explanatory. In summary, here is what happens:  a message is created with the create_message method; the message is added to the specified thread_id as a user message the thread is run on the agent specified by the agent.id to know if the run is finished, polling is used; the create_and_process_run hides that complexity for you messages are retrieved from the thread but only the last assistant message is used we extract the text and image from the message if it is present when there is an image, we use get_file_content to retrieve the file content from the API; that functions returns an Iterator of bytes that are joined together and base64 encoded the message and image are returned Testing the API When we POST to the threads enpoint, this is the response:  {   \"thread_id\": \"thread_meYRMrkRtUiI1u0ZGH0z7PEN\" } We can use that id to post to the messages endpoint. For example in a .http file:  POST http://localhost:8000/threads/thread_meYRMrkRtUiI1u0ZGH0z7PEN/messages Content-Type: application/json   {     \"message\": \"Create a sample bar chart\" } The response to the above request should be something like below:  {   \"assistant_text\": \"Here is a sample bar chart displaying four categories (A to D) with their corresponding values. If you need any modifications or another type of chart, just let me know!\",   \"assistant_image\": \"iVBORw0KGgoAAAANSUhEUgAABpYAAARNCAYAAABYAnNeAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAB7CAAAewgFu0HU+AADWf0lEQ...\" } In this case, the model determined that the code interpreter should be used to create the sample bar chart. When you ask for something simpler, like the weather, you get the following response:  {   \"assistant_text\": \"The current temperature in London is 11.4Â°C. If you need more information or updates, feel free to ask!\",   \"assistant_image\": null } In this case, our custom weather function was used to answer. The assistant determines what tools should be used to provide an answer.  Integration in a web app The GitHub repository contains a sample UI to try the API:   Sample UI and a chat combining weather and plotting Beautiful, is it not? ðŸ˜‚  Conclusion The Azure AI Agent service makes it relatively easy to create an agent that has access to knowledge and tools. The assistant decides on its own how to use the knowledge and tools. However, you can steer the assistant via its instructions and influence how the assistant behaves.  The SDK makes it easy to add your own custom functions as tools, next to the built-in tools that it supports. Soon, there will be an Agent Service user interface in Azure AI Foundry. You will be able to create agents in code that reference the agents you have built in Foundry.  To try it for yourself, use the code in the GitHub repo. Note that the code is demo code with limited error handling. Itâ€™s merely meant to demonstrate first steps.  Enjoy and let me know what you build with it! ðŸ˜‰"
                  }
                ],
                "temperature": 1.0,
                "top_p": 1.0,
                "n": 1,
                "stream": false,
                "presence_penalty": 0.0,
                "frequency_penalty": 0.0,
                "user": ""
              },
              "output": {
                "id": "chatcmpl-AnSAuKhERHNt0o6UwxPhqwaMh1a0Y",
                "choices": [
                  {
                    "finish_reason": "stop",
                    "index": 0,
                    "logprobs": null,
                    "message": {
                      "content": "\"Azure AI Agents: Build Intelligent Bots with Ease Using Foundry SDK\"",
                      "refusal": null,
                      "role": "assistant",
                      "audio": null,
                      "function_call": null,
                      "tool_calls": null
                    },
                    "content_filter_results": {
                      "hate": {
                        "filtered": false,
                        "severity": "safe"
                      },
                      "self_harm": {
                        "filtered": false,
                        "severity": "safe"
                      },
                      "sexual": {
                        "filtered": false,
                        "severity": "safe"
                      },
                      "violence": {
                        "filtered": false,
                        "severity": "safe"
                      }
                    }
                  }
                ],
                "created": 1736349740,
                "model": "gpt-4o-2024-08-06",
                "object": "chat.completion",
                "service_tier": null,
                "system_fingerprint": "fp_4e924a4b48",
                "usage": {
                  "completion_tokens": 15,
                  "prompt_tokens": 2565,
                  "total_tokens": 2580,
                  "completion_tokens_details": null,
                  "prompt_tokens_details": null
                },
                "prompt_filter_results": [
                  {
                    "prompt_index": 0,
                    "content_filter_results": {
                      "hate": {
                        "filtered": false,
                        "severity": "safe"
                      },
                      "jailbreak": {
                        "filtered": false,
                        "detected": false
                      },
                      "self_harm": {
                        "filtered": false,
                        "severity": "safe"
                      },
                      "sexual": {
                        "filtered": false,
                        "severity": "safe"
                      },
                      "violence": {
                        "filtered": false,
                        "severity": "safe"
                      }
                    }
                  }
                ]
              },
              "start_time": 1736346140.06327,
              "end_time": 1736346141.162999,
              "error": null,
              "children": [],
              "node_name": null,
              "parent_id": "28403cba-06b1-475d-9c4e-01f5496c213a",
              "id": "2487bc57-a0b6-442b-96ed-f8554add290a",
              "function": "openai.resources.chat.completions.Completions.create",
              "system_metrics": {
                "completion_tokens": 15,
                "prompt_tokens": 2565,
                "total_tokens": 2580
              }
            }
          ],
          "node_name": "generate_title",
          "parent_id": "",
          "id": "28403cba-06b1-475d-9c4e-01f5496c213a",
          "function": "AzureOpenAI.chat",
          "system_metrics": {
            "completion_tokens": 15,
            "prompt_tokens": 2565,
            "total_tokens": 2580
          }
        }
      ],
      "cached_run_id": null,
      "cached_flow_run_id": null,
      "logs": {
        "stdout": "",
        "stderr": ""
      },
      "system_metrics": {
        "completion_tokens": 15,
        "prompt_tokens": 2565,
        "total_tokens": 2580,
        "duration": 1.102659
      },
      "result": "\"Azure AI Agents: Build Intelligent Bots with Ease Using Foundry SDK\"",
      "message_format": "basic"
    }
  ]
}